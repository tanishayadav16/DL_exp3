{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2J8iWIu0xA7FmTbUzfR1D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishayadav16/DL_exp3/blob/main/exp_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noc2jJtFsnj7",
        "outputId": "77b728af-c645-438b-ad25-ce18b4a86a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1. Bag-of-Words (Count Vectorizer) ---\n",
            "Feature Names (Words): ['and' 'bacon' 'beans' 'beautiful' 'blue' 'breakfast' 'brown' 'dog' 'eggs'\n",
            " 'fox' 'green' 'ham' 'has' 'is' 'jumps' 'king' 'lazy' 'love' 'over'\n",
            " 'quick' 'sausages' 'sky' 'the' 'this' 'toast' 'today' 'very']\n",
            "Bag-of-Words Matrix:\n",
            " [[1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
            " [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 2 0 0 0 0]\n",
            " [1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
            " [1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
            " [1 0 0 0 1 0 1 1 0 1 0 0 0 2 0 0 1 0 0 1 0 0 2 0 0 0 0]\n",
            " [1 0 0 1 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 0 1 2]]\n",
            "\n",
            "--- 2. Bag-of-Bigrams (2-grams) ---\n",
            "Feature Names (Bigrams): ['and bacon' 'and beans' 'and beautiful' 'and the' 'bacon eggs'\n",
            " 'beautiful sky' 'beautiful today' 'blue and' 'blue dog' 'breakfast has'\n",
            " 'brown fox' 'dog is' 'eggs ham' 'eggs toast' 'fox is' 'fox jumps'\n",
            " 'green eggs' 'ham bacon' 'ham sausages' 'has sausages' 'is blue'\n",
            " 'is lazy' 'is quick' 'is very' 'jumps over' 'king breakfast' 'lazy dog'\n",
            " 'love green' 'love this' 'over the' 'quick and' 'quick brown'\n",
            " 'sausages and' 'sausages ham' 'sky is' 'the blue' 'the brown' 'the lazy'\n",
            " 'the quick' 'the sky' 'this blue' 'toast and' 'very beautiful'\n",
            " 'very blue']\n",
            "Bag-of-Bigrams Matrix:\n",
            " [[0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            "  0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
            "  0 1 1 0 0 0 0 0]\n",
            " [0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
            "  0 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
            "  0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
            "  1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0\n",
            "  0 0 0 2 0 0 1 1]]\n",
            "\n",
            "--- 3. Bag-of-Words (TF-IDF Vectorizer) ---\n",
            "Feature Names (Words): ['and' 'bacon' 'beans' 'beautiful' 'blue' 'breakfast' 'brown' 'dog' 'eggs'\n",
            " 'fox' 'green' 'ham' 'has' 'is' 'jumps' 'king' 'lazy' 'love' 'over'\n",
            " 'quick' 'sausages' 'sky' 'the' 'this' 'toast' 'today' 'very']\n",
            "TF-IDF Matrix:\n",
            " [[0.30073434 0.         0.         0.44920459 0.39000294 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.44920459 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.44920459 0.39000294 0.\n",
            "  0.         0.         0.        ]\n",
            " [0.26144771 0.         0.         0.39052245 0.33905465 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.45687599\n",
            "  0.         0.         0.         0.39052245 0.         0.55039605\n",
            "  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.31457246 0.31457246 0.         0.31457246 0.         0.\n",
            "  0.         0.         0.37896375 0.         0.31457246 0.\n",
            "  0.37896375 0.31457246 0.         0.         0.46689805 0.\n",
            "  0.         0.         0.        ]\n",
            " [0.16813526 0.29381386 0.35395598 0.         0.         0.35395598\n",
            "  0.         0.         0.29381386 0.         0.         0.29381386\n",
            "  0.35395598 0.         0.         0.35395598 0.         0.\n",
            "  0.         0.         0.29381386 0.         0.         0.\n",
            "  0.35395598 0.         0.        ]\n",
            " [0.21979174 0.3840828  0.         0.         0.         0.\n",
            "  0.         0.         0.3840828  0.         0.46270249 0.3840828\n",
            "  0.         0.         0.         0.         0.         0.3840828\n",
            "  0.         0.         0.3840828  0.         0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.17251151 0.         0.         0.         0.22371904 0.\n",
            "  0.30146131 0.30146131 0.         0.30146131 0.         0.\n",
            "  0.         0.51535826 0.         0.         0.30146131 0.\n",
            "  0.         0.30146131 0.         0.         0.44743808 0.\n",
            "  0.         0.         0.        ]\n",
            " [0.13914681 0.         0.         0.20784252 0.1804505  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.41568504 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.41568504 0.360901   0.\n",
            "  0.         0.2929299  0.5858598 ]]\n"
          ]
        }
      ],
      "source": [
        "# ✅ Install if not installed\n",
        "# pip install scikit-learn\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# ✅ Sample text data\n",
        "documents = [\n",
        "    \"The sky is blue and beautiful.\",\n",
        "    \"Love this blue and beautiful sky!\",\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "    \"I love green eggs, ham, sausages and bacon!\",\n",
        "    \"The brown fox is quick and the blue dog is lazy!\",\n",
        "    \"The sky is very blue and the sky is very beautiful today\"\n",
        "]\n",
        "\n",
        "# 1️⃣ Bag-of-Words using CountVectorizer\n",
        "print(\"\\n--- 1. Bag-of-Words (Count Vectorizer) ---\")\n",
        "count_vectorizer = CountVectorizer()\n",
        "bow = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Feature Names (Words):\", count_vectorizer.get_feature_names_out())\n",
        "print(\"Bag-of-Words Matrix:\\n\", bow.toarray())\n",
        "\n",
        "# 2️⃣ Bag-of-N-Grams using CountVectorizer (e.g., bigrams: ngram_range=(2,2))\n",
        "print(\"\\n--- 2. Bag-of-Bigrams (2-grams) ---\")\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
        "bigrams = bigram_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Feature Names (Bigrams):\", bigram_vectorizer.get_feature_names_out())\n",
        "print(\"Bag-of-Bigrams Matrix:\\n\", bigrams.toarray())\n",
        "\n",
        "# 3️⃣ Bag-of-Words using TF-IDF Vectorizer\n",
        "print(\"\\n--- 3. Bag-of-Words (TF-IDF Vectorizer) ---\")\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Feature Names (Words):\", tfidf_vectorizer.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix:\\n\", tfidf.toarray())\n"
      ]
    }
  ]
}